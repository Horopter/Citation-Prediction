{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {
    "id": "header",
    "papermill": {
     "duration": 0.004831,
     "end_time": "2025-11-20T00:15:05.436635",
     "exception": false,
     "start_time": "2025-11-20T00:15:05.431804",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Model: PyTorch MLP with All Features (No PCA)\n",
    "\n",
    "This notebook trains a **PyTorch-based Multi-Layer Perceptron (MLP)** classifier on all available features (regular + all embeddings) with comprehensive preprocessing:\n",
    "- âœ… All regular features\n",
    "- âœ… All embedding families (no PCA compression)\n",
    "- âœ… Feature scaling (StandardScaler)\n",
    "- âœ… Fixed Hyperparameters with CV Validation\n",
    "- âœ… Threshold Fine-tuning\n",
    "- âœ… Model Saving\n",
    "- âœ… Submission.csv Generation\n",
    "- âœ… OOM Safe with aggressive memory management\n",
    "- âœ… Class imbalance handled via pos_weight_tensor (no SMOTETomek for speed)\n",
    "- âœ… GPU acceleration with CPU fallback"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "navigation",
   "metadata": {
    "id": "navigation",
    "papermill": {
     "duration": 0.003726,
     "end_time": "2025-11-20T00:15:05.444561",
     "exception": false,
     "start_time": "2025-11-20T00:15:05.440835",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# ðŸ“‘ PyTorch MLP - Code Navigation Index\n",
    "\n",
    "## Quick Navigation\n",
    "- **[Setup](#1-setup)** - Imports, paths, device configuration, robustness utilities\n",
    "- **[Data Loading](#2-data-loading--feature-extraction)** - Load and split features (NO PCA)\n",
    "- **[Class Imbalance Info](#3-class-imbalance-info)** - Class imbalance statistics (handled via pos_weight_tensor)\n",
    "- **[Feature Scaling](#4-feature-scaling)** - StandardScaler normalization\n",
    "- **[Hyperparameter Selection](#5-hyperparameter-selection)** - Fixed hyperparameters with CV validation\n",
    "- **[Threshold Tuning](#6-threshold-tuning--final-evaluation)** - Optimal threshold finding\n",
    "- **[Model Saving](#7-save-model)** - Save model weights and metadata\n",
    "- **[Submission](#8-generate-submission)** - Generate test predictions\n",
    "\n",
    "## Model Type: PyTorch MLP (all features, no PCA)\n",
    "\n",
    "## Key Features\n",
    "âœ… GPU-friendly with CPU fallback  \n",
    "âœ… Aggressive garbage collection  \n",
    "âœ… OOM resistant with chunked processing  \n",
    "âœ… Kernel panic resistant (signal handlers, checkpoints)  \n",
    "âœ… Polars-only (no pandas)  \n",
    "âœ… Fixed hyperparameters with CV validation  \n",
    "âœ… Class imbalance handled via pos_weight_tensor (no SMOTETomek for speed)  \n",
    "âœ… Feature scaling & normalization  \n",
    "âœ… Fine-grained threshold optimization  \n",
    "âœ… Model weights saved  \n",
    "âœ… Chunked/batched data processing  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "setup_header",
   "metadata": {
    "id": "setup_header",
    "papermill": {
     "duration": 0.003695,
     "end_time": "2025-11-20T00:15:05.452174",
     "exception": false,
     "start_time": "2025-11-20T00:15:05.448479",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "imports",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-20T00:15:05.460611Z",
     "iopub.status.busy": "2025-11-20T00:15:05.460440Z",
     "iopub.status.idle": "2025-11-20T00:15:22.897788Z",
     "shell.execute_reply": "2025-11-20T00:15:22.897049Z"
    },
    "id": "imports",
    "papermill": {
     "duration": 17.44247,
     "end_time": "2025-11-20T00:15:22.898459",
     "exception": false,
     "start_time": "2025-11-20T00:15:05.455989",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import random\n",
    "import gc\n",
    "import numpy as np\n",
    "import polars as pl\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "from typing import Dict, Optional, Tuple\n",
    "import sys\n",
    "import time\n",
    "import json\n",
    "import pickle\n",
    "import signal\n",
    "import atexit\n",
    "from functools import wraps\n",
    "from datetime import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "startup",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-20T00:15:22.911261Z",
     "iopub.status.busy": "2025-11-20T00:15:22.911001Z",
     "iopub.status.idle": "2025-11-20T00:15:23.218970Z",
     "shell.execute_reply": "2025-11-20T00:15:23.218333Z"
    },
    "id": "startup",
    "papermill": {
     "duration": 0.313219,
     "end_time": "2025-11-20T00:15:23.219561",
     "exception": false,
     "start_time": "2025-11-20T00:15:22.906342",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "MODEL_PYTORCH_MLP EXECUTION STARTED\n",
      "Start Time: 2025-11-19 19:15:22\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# STARTUP & REPRODUCIBILITY\n",
    "# =========================\n",
    "\n",
    "TOTAL_START_TIME = time.time()\n",
    "START_TIME_STR = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"MODEL_PYTORCH_MLP EXECUTION STARTED\")\n",
    "print(f\"Start Time: {START_TIME_STR}\")\n",
    "print(f\"{'='*80}\\n\")\n",
    "\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(SEED)\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "paths",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-20T00:15:23.228901Z",
     "iopub.status.busy": "2025-11-20T00:15:23.228652Z",
     "iopub.status.idle": "2025-11-20T00:15:23.234288Z",
     "shell.execute_reply": "2025-11-20T00:15:23.233766Z"
    },
    "id": "paths",
    "papermill": {
     "duration": 0.011225,
     "end_time": "2025-11-20T00:15:23.234997",
     "exception": false,
     "start_time": "2025-11-20T00:15:23.223772",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROJECT_ROOT: /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/Kaggle_2\n",
      "MODEL_READY_DIR: /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/Kaggle_2/data/model_ready\n"
     ]
    }
   ],
   "source": [
    "# ==============\n",
    "# PATH MANAGEMENT\n",
    "# ==============\n",
    "\n",
    "current = Path(os.getcwd())\n",
    "PROJECT_ROOT = current\n",
    "for _ in range(5):\n",
    "    if (PROJECT_ROOT / \"data\").exists():\n",
    "        break\n",
    "    PROJECT_ROOT = PROJECT_ROOT.parent\n",
    "else:\n",
    "    PROJECT_ROOT = current.parent.parent\n",
    "\n",
    "MODEL_READY_DIR = PROJECT_ROOT / \"data\" / \"model_ready\"\n",
    "MODEL_SAVE_DIR = PROJECT_ROOT / \"models\" / \"saved_models\"\n",
    "SUBMISSION_DIR = PROJECT_ROOT / \"data\" / \"submission_files\"\n",
    "MODEL_SAVE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "SUBMISSION_DIR.mkdir(parents=True, exist_ok=True)\n",
    "utils_path = PROJECT_ROOT / \"src\" / \"utils\"\n",
    "print(\"PROJECT_ROOT:\", PROJECT_ROOT)\n",
    "print(\"MODEL_READY_DIR:\", MODEL_READY_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ml_libs",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-20T00:15:23.244237Z",
     "iopub.status.busy": "2025-11-20T00:15:23.244060Z",
     "iopub.status.idle": "2025-11-20T00:15:41.751204Z",
     "shell.execute_reply": "2025-11-20T00:15:41.750575Z"
    },
    "id": "ml_libs",
    "papermill": {
     "duration": 18.512837,
     "end_time": "2025-11-20T00:15:41.752110",
     "exception": false,
     "start_time": "2025-11-20T00:15:23.239273",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ==========\n",
    "# ML LIBRARIES\n",
    "# ==========\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import f1_score, roc_auc_score, classification_report, precision_recall_curve, roc_curve, confusion_matrix\n",
    "# SMOTETomek removed - using pos_weight_tensor instead for speed (173x faster on full features)\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# ==========\n",
    "# VISUALIZATION LIBRARIES\n",
    "# ==========\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import display, Image\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "memory_utils",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-20T00:15:41.763548Z",
     "iopub.status.busy": "2025-11-20T00:15:41.763243Z",
     "iopub.status.idle": "2025-11-20T00:15:41.771096Z",
     "shell.execute_reply": "2025-11-20T00:15:41.770566Z"
    },
    "id": "memory_utils",
    "papermill": {
     "duration": 0.013693,
     "end_time": "2025-11-20T00:15:41.771790",
     "exception": false,
     "start_time": "2025-11-20T00:15:41.758097",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ Using fallback memory utilities\n",
      "ðŸ’¾ Memory: 0.61 GB (RAM) | 0.00/0.00 GB (GPU used/reserved)\n"
     ]
    }
   ],
   "source": [
    "# ===============================\n",
    "# MEMORY UTILITIES (FALLBACK DEFS)\n",
    "# ===============================\n",
    "try:\n",
    "    from model_training_utils import cleanup_memory, memory_usage, check_memory_safe\n",
    "    print(\"âœ… Memory utilities imported from shared module\")\n",
    "except ImportError:\n",
    "    def cleanup_memory():\n",
    "        \"\"\"Aggressive memory cleanup for both CPU and GPU.\"\"\"\n",
    "        gc.collect()\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "            torch.cuda.synchronize()\n",
    "            torch.cuda.ipc_collect()\n",
    "        gc.collect()\n",
    "    \n",
    "    def memory_usage():\n",
    "        \"\"\"Display current memory usage statistics.\"\"\"\n",
    "        try:\n",
    "            import psutil\n",
    "            process = psutil.Process(os.getpid())\n",
    "            mem_gb = process.memory_info().rss / 1024**3\n",
    "            print(f\"ðŸ’¾ Memory: {mem_gb:.2f} GB (RAM)\", end=\"\")\n",
    "            if torch.cuda.is_available():\n",
    "                gpu_mem = torch.cuda.memory_allocated() / 1024**3\n",
    "                gpu_reserved = torch.cuda.memory_reserved() / 1024**3\n",
    "                print(f\" | {gpu_mem:.2f}/{gpu_reserved:.2f} GB (GPU used/reserved)\")\n",
    "            else:\n",
    "                print()\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    def check_memory_safe(ram_threshold_gb=0.85, gpu_threshold=0.80):\n",
    "        \"\"\"Check if memory usage is safe for operations.\"\"\"\n",
    "        try:\n",
    "            import psutil\n",
    "            process = psutil.Process(os.getpid())\n",
    "            ram_gb = process.memory_info().rss / 1024**3\n",
    "            total_ram = psutil.virtual_memory().total / 1024**3\n",
    "            ram_ratio = ram_gb / total_ram if total_ram > 0 else 0\n",
    "            gpu_ratio = 0\n",
    "            if torch.cuda.is_available():\n",
    "                gpu_used = torch.cuda.memory_allocated() / 1024**3\n",
    "                gpu_total = torch.cuda.get_device_properties(0).total_memory / 1024**3\n",
    "                gpu_ratio = gpu_used / gpu_total if gpu_total > 0 else 0\n",
    "            is_safe = ram_ratio < ram_threshold_gb and gpu_ratio < gpu_threshold\n",
    "            return is_safe, {\"ram_gb\": ram_gb, \"ram_ratio\": ram_ratio, \"gpu_ratio\": gpu_ratio}\n",
    "        except:\n",
    "            return True, {}\n",
    "    \n",
    "    print(\"âš ï¸ Using fallback memory utilities\")\n",
    "\n",
    "memory_usage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "robustness_utils",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-20T00:15:41.781301Z",
     "iopub.status.busy": "2025-11-20T00:15:41.781124Z",
     "iopub.status.idle": "2025-11-20T00:15:41.799926Z",
     "shell.execute_reply": "2025-11-20T00:15:41.799382Z"
    },
    "id": "robustness_utils",
    "papermill": {
     "duration": 0.024559,
     "end_time": "2025-11-20T00:15:41.800573",
     "exception": false,
     "start_time": "2025-11-20T00:15:41.776014",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Enhanced robustness utilities loaded\n",
      "âœ… Training robustness wrappers loaded\n"
     ]
    }
   ],
   "source": [
    "# ===============================\n",
    "# ROBUSTNESS/CHECKPOINT UTILITIES\n",
    "# ===============================\n",
    "\n",
    "_checkpoint_state = {\n",
    "    \"pca_complete\": False,\n",
    "    \"scaling_complete\": False,\n",
    "    \"cv_complete\": False,\n",
    "    \"final_model_trained\": False,\n",
    "    \"last_saved_checkpoint\": None,\n",
    "}\n",
    "\n",
    "def save_checkpoint(state_name: str, data: dict, checkpoint_dir: Path = None):\n",
    "    \"\"\"Save checkpoint to resume from failures.\"\"\"\n",
    "    if checkpoint_dir is None:\n",
    "        checkpoint_dir = PROJECT_ROOT / \"data\" / \"checkpoints\"\n",
    "    checkpoint_dir.mkdir(parents=True, exist_ok=True)\n",
    "    checkpoint_path = checkpoint_dir / f\"model_pytorch_mlp_checkpoint_{state_name}.pkl\"\n",
    "    try:\n",
    "        with open(checkpoint_path, \"wb\") as f:\n",
    "            pickle.dump(data, f)\n",
    "        _checkpoint_state[\"last_saved_checkpoint\"] = checkpoint_path\n",
    "        print(f\"âœ… Checkpoint saved: {checkpoint_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ Failed to save checkpoint: {e}\")\n",
    "\n",
    "def load_checkpoint(state_name: str, checkpoint_dir: Path = None):\n",
    "    \"\"\"Load checkpoint to resume from failures.\"\"\"\n",
    "    if checkpoint_dir is None:\n",
    "        checkpoint_dir = PROJECT_ROOT / \"data\" / \"checkpoints\"\n",
    "    checkpoint_path = checkpoint_dir / f\"model_pytorch_mlp_checkpoint_{state_name}.pkl\"\n",
    "    if checkpoint_path.exists():\n",
    "        try:\n",
    "            with open(checkpoint_path, \"rb\") as f:\n",
    "                data = pickle.load(f)\n",
    "            print(f\"âœ… Checkpoint loaded: {checkpoint_path}\")\n",
    "            return data\n",
    "        except Exception as e:\n",
    "            print(f\"âš ï¸ Failed to load checkpoint: {e}\")\n",
    "    return None\n",
    "\n",
    "def safe_operation(operation_name: str, max_retries: int = 3, checkpoint_on_success: bool = False):\n",
    "    \"\"\"Decorator for safe operations with retry and checkpoint support.\"\"\"\n",
    "    def decorator(func):\n",
    "        @wraps(func)\n",
    "        def wrapper(*args, **kwargs):\n",
    "            for attempt in range(max_retries):\n",
    "                try:\n",
    "                    is_safe, mem_info = check_memory_safe(ram_threshold_gb=0.80, gpu_threshold=0.75)\n",
    "                    if not is_safe:\n",
    "                        cleanup_memory()\n",
    "                        if torch.cuda.is_available():\n",
    "                            torch.cuda.empty_cache()\n",
    "                        time.sleep(1)\n",
    "                    result = func(*args, **kwargs)\n",
    "                    cleanup_memory()\n",
    "                    if checkpoint_on_success:\n",
    "                        save_checkpoint(operation_name, {\"status\": \"complete\", \"result\": result})\n",
    "                    return result\n",
    "                except (MemoryError, RuntimeError) as e:\n",
    "                    error_msg = str(e).lower()\n",
    "                    if \"out of memory\" in error_msg or \"oom\" in error_msg:\n",
    "                        if attempt < max_retries - 1:\n",
    "                            cleanup_memory()\n",
    "                            if torch.cuda.is_available():\n",
    "                                torch.cuda.empty_cache()\n",
    "                            time.sleep(2)\n",
    "                            continue\n",
    "                        else:\n",
    "                            raise\n",
    "                    else:\n",
    "                        raise\n",
    "                except Exception as e:\n",
    "                    if attempt < max_retries - 1:\n",
    "                        cleanup_memory()\n",
    "                        time.sleep(1)\n",
    "                        continue\n",
    "                    else:\n",
    "                        raise\n",
    "            return None\n",
    "        return wrapper\n",
    "    return decorator\n",
    "\n",
    "def chunked_operation(\n",
    "    data,\n",
    "    operation_func,\n",
    "    chunk_size: int = 10000,\n",
    "    progress_every: int = 10,\n",
    "    operation_name: str = \"operation\",\n",
    "):\n",
    "    \"\"\"Execute operation on data in chunks with progress tracking.\"\"\"\n",
    "    total_chunks = (len(data) + chunk_size - 1) // chunk_size\n",
    "    results = []\n",
    "    for i in range(0, len(data), chunk_size):\n",
    "        chunk_num = i // chunk_size + 1\n",
    "        chunk = data[i : i + chunk_size]\n",
    "        try:\n",
    "            is_safe, mem_info = check_memory_safe(ram_threshold_gb=0.85, gpu_threshold=0.80)\n",
    "            if not is_safe:\n",
    "                cleanup_memory()\n",
    "                if torch.cuda.is_available():\n",
    "                    torch.cuda.empty_cache()\n",
    "                time.sleep(0.5)\n",
    "            chunk_result = operation_func(chunk)\n",
    "            results.append(chunk_result)\n",
    "            if chunk_num % progress_every == 0 or chunk_num == total_chunks:\n",
    "                print(f\"  Progress: {chunk_num}/{total_chunks} chunks ({chunk_num*100//total_chunks}%)\")\n",
    "            del chunk\n",
    "            if chunk_num % 5 == 0:\n",
    "                cleanup_memory()\n",
    "        except (MemoryError, RuntimeError) as e:\n",
    "            error_msg = str(e).lower()\n",
    "            if \"out of memory\" in error_msg or \"oom\" in error_msg:\n",
    "                cleanup_memory()\n",
    "                if torch.cuda.is_available():\n",
    "                    torch.cuda.empty_cache()\n",
    "                smaller_chunk_size = max(1000, chunk_size // 2)\n",
    "                if smaller_chunk_size < chunk_size:\n",
    "                    return chunked_operation(\n",
    "                        data[i:],\n",
    "                        operation_func,\n",
    "                        chunk_size=smaller_chunk_size,\n",
    "                        progress_every=progress_every,\n",
    "                        operation_name=operation_name,\n",
    "                    )\n",
    "                else:\n",
    "                    raise\n",
    "            else:\n",
    "                raise\n",
    "    return results\n",
    "\n",
    "def emergency_cleanup():\n",
    "    \"\"\"Emergency cleanup on exit.\"\"\"\n",
    "    try:\n",
    "        cleanup_memory()\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "        print(\"âœ… Emergency cleanup completed\")\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "atexit.register(emergency_cleanup)\n",
    "\n",
    "def signal_handler(signum, frame):\n",
    "    \"\"\"Handle signals for graceful shutdown.\"\"\"\n",
    "    print(f\"âš ï¸ Received signal {signum}, saving checkpoint...\")\n",
    "    save_checkpoint(\"emergency\", {\"status\": \"signal_received\", \"signal\": signum})\n",
    "    emergency_cleanup()\n",
    "    raise KeyboardInterrupt\n",
    "\n",
    "try:\n",
    "    signal.signal(signal.SIGINT, signal_handler)\n",
    "    signal.signal(signal.SIGTERM, signal_handler)\n",
    "except:\n",
    "    pass\n",
    "print(\"âœ… Enhanced robustness utilities loaded\")\n",
    "\n",
    "def safe_prediction(predict_func, *args, **kwargs):\n",
    "    \"\"\"Execute prediction with chunked processing.\"\"\"\n",
    "    try:\n",
    "        is_safe, mem_info = check_memory_safe(ram_threshold_gb=0.85, gpu_threshold=0.80)\n",
    "        if not is_safe:\n",
    "            cleanup_memory()\n",
    "        if \"X\" in kwargs and len(kwargs[\"X\"]) > 50000:\n",
    "            X = kwargs[\"X\"]\n",
    "            chunk_size = 10000\n",
    "            predictions = []\n",
    "            for i in range(0, len(X), chunk_size):\n",
    "                chunk = X[i : i + chunk_size]\n",
    "                kwargs[\"X\"] = chunk\n",
    "                chunk_preds = predict_func(*args, **kwargs)\n",
    "                predictions.append(chunk_preds)\n",
    "                del chunk, chunk_preds\n",
    "                if i % (chunk_size * 5) == 0:\n",
    "                    cleanup_memory()\n",
    "            return np.concatenate(predictions)\n",
    "        else:\n",
    "            return predict_func(*args, **kwargs)\n",
    "    except (MemoryError, RuntimeError) as e:\n",
    "        error_msg = str(e).lower()\n",
    "        if \"out of memory\" in error_msg or \"oom\" in error_msg:\n",
    "            cleanup_memory()\n",
    "            if torch.cuda.is_available():\n",
    "                torch.cuda.empty_cache()\n",
    "            if \"X\" in kwargs:\n",
    "                X = kwargs[\"X\"]\n",
    "                chunk_size = 5000\n",
    "                predictions = []\n",
    "                for i in range(0, len(X), chunk_size):\n",
    "                    chunk = X[i : i + chunk_size]\n",
    "                    kwargs[\"X\"] = chunk\n",
    "                    chunk_preds = predict_func(*args, **kwargs)\n",
    "                    predictions.append(chunk_preds)\n",
    "                    del chunk, chunk_preds\n",
    "                    cleanup_memory()\n",
    "                return np.concatenate(predictions)\n",
    "            else:\n",
    "                raise\n",
    "        else:\n",
    "            raise\n",
    "\n",
    "print(\"âœ… Training robustness wrappers loaded\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "data_loading_header",
   "metadata": {
    "id": "data_loading_header",
    "papermill": {
     "duration": 0.004114,
     "end_time": "2025-11-20T00:15:41.809019",
     "exception": false,
     "start_time": "2025-11-20T00:15:41.804905",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 2. Data Loading & Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "data_loading",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-20T00:15:41.818425Z",
     "iopub.status.busy": "2025-11-20T00:15:41.818254Z",
     "iopub.status.idle": "2025-11-20T00:17:06.620615Z",
     "shell.execute_reply": "2025-11-20T00:17:06.619892Z"
    },
    "id": "data_loading",
    "papermill": {
     "duration": 85.487678,
     "end_time": "2025-11-20T00:17:07.301141",
     "exception": false,
     "start_time": "2025-11-20T00:15:41.813463",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "PHASE 1: Data Loading\n",
      "================================================================================\n",
      "Loading train from /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/Kaggle_2/data/model_ready/train_model_ready.parquet\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading val from /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/Kaggle_2/data/model_ready/val_model_ready.parquet\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“Š Data Summary:\n",
      "  Regular features: 54\n",
      "  Total features: 1974\n",
      "  Embedding sent_transformer_: 384 dims (NO PCA)\n",
      "  Embedding sent_transformer_: 384 dims\n",
      "  Embedding scibert_: 768 dims (NO PCA)\n",
      "  Embedding scibert_: 768 dims\n",
      "  Embedding specter2_: 768 dims (NO PCA)\n",
      "  Embedding specter2_: 768 dims\n",
      "  Train samples: 960000, Positive: 65808, Negative: 894192\n",
      "  Val samples: 120000, Positive: 8075, Negative: 111925\n",
      "\n",
      "â±ï¸  Data Loading Time: 77.18 seconds (1.29 minutes)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ’¾ Memory: 48.34 GB (RAM) | 0.00/0.00 GB (GPU used/reserved)\n"
     ]
    }
   ],
   "source": [
    "def load_parquet_split(split: str) -> pl.DataFrame:\n",
    "    \"\"\"Load a model_ready parquet split with error handling.\"\"\"\n",
    "    try:\n",
    "        path = MODEL_READY_DIR / f\"{split}_model_ready.parquet\"\n",
    "        if not path.exists():\n",
    "            alt = MODEL_READY_DIR / f\"{split}_model_ready_reduced.parquet\"\n",
    "            if alt.exists():\n",
    "                path = alt\n",
    "            else:\n",
    "                raise FileNotFoundError(f\"Could not find {split} data\")\n",
    "        print(f\"Loading {split} from {path}\")\n",
    "        return pl.read_parquet(path)\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error loading {split}: {e}\")\n",
    "        raise\n",
    "\n",
    "\n",
    "def split_features_reg_and_all_emb(df: pl.DataFrame):\n",
    "    \"\"\"Split features into regular and embedding families.\"\"\"\n",
    "    cols = df.columns\n",
    "    dtypes = df.dtypes\n",
    "    label = df[\"label\"].to_numpy() if \"label\" in cols else None\n",
    "\n",
    "    reg_cols = []\n",
    "    EMBEDDING_FAMILY_PREFIXES = [\"sent_transformer_\", \"scibert_\", \"specter_\", \"specter2_\", \"ner_\"]\n",
    "    emb_family_to_cols = {p: [] for p in EMBEDDING_FAMILY_PREFIXES}\n",
    "\n",
    "    NUMERIC_DTYPES = {\n",
    "        pl.Int8,\n",
    "        pl.Int16,\n",
    "        pl.Int32,\n",
    "        pl.Int64,\n",
    "        pl.UInt8,\n",
    "        pl.UInt16,\n",
    "        pl.UInt32,\n",
    "        pl.UInt64,\n",
    "        pl.Float32,\n",
    "        pl.Float64,\n",
    "    }\n",
    "\n",
    "    for c, dt in zip(cols, dtypes):\n",
    "        if c in (\"id\", \"label\"):\n",
    "            continue\n",
    "        matched = False\n",
    "        for p in EMBEDDING_FAMILY_PREFIXES:\n",
    "            if c.startswith(p):\n",
    "                emb_family_to_cols[p].append(c)\n",
    "                matched = True\n",
    "                break\n",
    "        if not matched and dt in NUMERIC_DTYPES:\n",
    "            reg_cols.append(c)\n",
    "\n",
    "    X_reg = df.select(reg_cols).to_numpy() if reg_cols else None\n",
    "    X_emb_families = {}\n",
    "    for p, clist in emb_family_to_cols.items():\n",
    "        if clist:\n",
    "            X_emb_families[p] = df.select(clist).to_numpy()\n",
    "\n",
    "    return X_reg, X_emb_families, label, reg_cols, emb_family_to_cols\n",
    "\n",
    "\n",
    "# Load data\n",
    "try:\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"PHASE 1: Data Loading\")\n",
    "    print(\"=\" * 80)\n",
    "    phase_start = time.time()\n",
    "    \n",
    "    train_df = load_parquet_split(\"train\")\n",
    "    val_df = load_parquet_split(\"val\")\n",
    "\n",
    "    X_reg_train, X_emb_train_fams, y_train, reg_cols, emb_family_to_cols = (\n",
    "        split_features_reg_and_all_emb(train_df)\n",
    "    )\n",
    "    X_reg_val, X_emb_val_fams, y_val, _, _ = split_features_reg_and_all_emb(val_df)\n",
    "\n",
    "    # Combine regular + ALL embeddings (NO PCA)\n",
    "    X_emb_train_list = []\n",
    "    X_emb_val_list = []\n",
    "    for fam in X_emb_train_fams.keys():\n",
    "        X_emb_train_list.append(X_emb_train_fams[fam])\n",
    "        X_emb_val_list.append(X_emb_val_fams[fam])\n",
    "    \n",
    "    X_emb_train = np.hstack(X_emb_train_list) if X_emb_train_list else None\n",
    "    X_emb_val = np.hstack(X_emb_val_list) if X_emb_val_list else None\n",
    "\n",
    "    if X_reg_train is not None:\n",
    "        X_train = np.hstack([X_reg_train, X_emb_train]) if X_emb_train is not None else X_reg_train\n",
    "        X_val = np.hstack([X_reg_val, X_emb_val]) if X_emb_val is not None else X_reg_val\n",
    "    else:\n",
    "        X_train = X_emb_train\n",
    "        X_val = X_emb_val\n",
    "\n",
    "    phase_time = time.time() - phase_start\n",
    "    print(f\"\\nðŸ“Š Data Summary:\")\n",
    "    print(f\"  Regular features: {len(reg_cols)}\")\n",
    "    print(f\"  Total features: {X_train.shape[1]}\")\n",
    "    for fam, arr in X_emb_train_fams.items():\n",
    "        print(f\"  Embedding {fam}: {arr.shape[1]} dims (NO PCA)\")\n",
    "        print(f\"  Embedding {fam}: {arr.shape[1]} dims\")\n",
    "    print(\n",
    "        f\"  Train samples: {len(y_train)}, Positive: {y_train.sum()}, Negative: {(y_train==0).sum()}\"\n",
    "    )\n",
    "    print(f\"  Val samples: {len(y_val)}, Positive: {y_val.sum()}, Negative: {(y_val==0).sum()}\")\n",
    "    print(f\"\\nâ±ï¸  Data Loading Time: {phase_time:.2f} seconds ({phase_time/60:.2f} minutes)\")\n",
    "\n",
    "    del train_df, val_df, X_reg_train, X_reg_val, X_emb_train_fams, X_emb_val_fams\n",
    "    del X_emb_train_list, X_emb_val_list, X_emb_train, X_emb_val\n",
    "    cleanup_memory()\n",
    "    memory_usage()\n",
    "except Exception as e:\n",
    "    print(f\"âŒ Error loading data: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "smote_header",
   "metadata": {
    "id": "smote_header",
    "papermill": {
     "duration": 0.011109,
     "end_time": "2025-11-20T00:17:07.354352",
     "exception": false,
     "start_time": "2025-11-20T00:17:07.343243",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 3. Class Imbalance Info (SMOTETomek Skipped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "smote",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-20T00:17:07.403834Z",
     "iopub.status.busy": "2025-11-20T00:17:07.403617Z",
     "iopub.status.idle": "2025-11-20T00:17:07.642320Z",
     "shell.execute_reply": "2025-11-20T00:17:07.641709Z"
    },
    "id": "smote",
    "papermill": {
     "duration": 0.288008,
     "end_time": "2025-11-20T00:17:07.651919",
     "exception": false,
     "start_time": "2025-11-20T00:17:07.363911",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "PHASE 2: Class Imbalance Info (SMOTETomek Skipped)\n",
      "================================================================================\n",
      "\n",
      "ðŸ“Š Class imbalance statistics:\n",
      "  Dataset: 960000 samples\n",
      "  Positive: 65808, Negative: 894192\n",
      "  Imbalance ratio: 13.59:1\n",
      "\n",
      "âœ… Class imbalance will be handled via:\n",
      "  â€¢ pos_weight_tensor in BCEWithLogitsLoss\n",
      "  â€¢ label_smoothing during training\n",
      "  â€¢ No SMOTETomek resampling (for speed)\n",
      "\n",
      "ðŸ’¡ Note: SMOTETomek skipped because:\n",
      "  â€¢ PyTorch MLP uses all 1974 features (no PCA)\n",
      "  â€¢ SMOTETomek complexity: O(n_featuresÂ² Ã— n_samples)\n",
      "  â€¢ Would be ~173x slower than XGBoost/LightGBM (which use PCA)\n",
      "  â€¢ pos_weight_tensor provides similar benefits without the cost\n",
      "\n",
      "âœ… Using original training data (no resampling)\n"
     ]
    }
   ],
   "source": [
    "# SMOTETomek SKIPPED - Using pos_weight_tensor instead for speed\n",
    "# Reason: SMOTETomek on 1974 features is ~173x slower than on 150 features (after PCA)\n",
    "# PyTorch MLP handles class imbalance via pos_weight_tensor in BCEWithLogitsLoss\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"PHASE 2: Class Imbalance Info (SMOTETomek Skipped)\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"\\nðŸ“Š Class imbalance statistics:\")\n",
    "print(f\"  Dataset: {len(X_train)} samples\")\n",
    "print(f\"  Positive: {y_train.sum()}, Negative: {(y_train == 0).sum()}\")\n",
    "print(f\"  Imbalance ratio: {(y_train == 0).sum() / max(y_train.sum(), 1):.2f}:1\")\n",
    "\n",
    "print(\"\\nâœ… Class imbalance will be handled via:\")\n",
    "print(\"  â€¢ pos_weight_tensor in BCEWithLogitsLoss\")\n",
    "print(\"  â€¢ label_smoothing during training\")\n",
    "print(\"  â€¢ No SMOTETomek resampling (for speed)\")\n",
    "\n",
    "print(\"\\nðŸ’¡ Note: SMOTETomek skipped because:\")\n",
    "print(\"  â€¢ PyTorch MLP uses all 1974 features (no PCA)\")\n",
    "print(\"  â€¢ SMOTETomek complexity: O(n_featuresÂ² Ã— n_samples)\")\n",
    "print(\"  â€¢ Would be ~173x slower than XGBoost/LightGBM (which use PCA)\")\n",
    "print(\"  â€¢ pos_weight_tensor provides similar benefits without the cost\")\n",
    "\n",
    "# Data remains unchanged - no resampling\n",
    "print(\"\\nâœ… Using original training data (no resampling)\")\n",
    "cleanup_memory()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "scaling_header",
   "metadata": {
    "id": "scaling_header",
    "papermill": {
     "duration": 0.00494,
     "end_time": "2025-11-20T00:17:07.673378",
     "exception": false,
     "start_time": "2025-11-20T00:17:07.668438",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 4. Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "scaling",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-20T00:17:07.683547Z",
     "iopub.status.busy": "2025-11-20T00:17:07.683360Z",
     "iopub.status.idle": "2025-11-20T00:19:09.457188Z",
     "shell.execute_reply": "2025-11-20T00:19:09.456063Z"
    },
    "id": "scaling",
    "papermill": {
     "duration": 121.807252,
     "end_time": "2025-11-20T00:19:09.485155",
     "exception": false,
     "start_time": "2025-11-20T00:17:07.677903",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "PHASE 3: Feature Scaling\n",
      "================================================================================\n",
      "\n",
      "ðŸ“Š Applying Feature Scaling to combined features...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fitting scaler on sample (50000 samples) for OOM protection...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Transforming train data in chunks (size=50000)...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Transforming val data in chunks (size=50000)...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  âœ… Scaling complete!\n",
      "\n",
      "â±ï¸  Feature Scaling Time: 82.08 seconds (1.37 minutes)\n",
      "ðŸ’¾ Memory: 48.52 GB (RAM) | 0.00/0.00 GB (GPU used/reserved)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"PHASE 3: Feature Scaling\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "phase_start = time.time()\n",
    "print(\"\\nðŸ“Š Applying Feature Scaling to combined features...\")\n",
    "\n",
    "# Store raw (unscaled) data for CV Pipeline (scaler will be fit per fold)\n",
    "X_train_raw = X_train.copy()\n",
    "X_val_raw = X_val.copy()\n",
    "y_train_raw = y_train.copy()\n",
    "y_val_raw = y_val.copy()\n",
    "\n",
    "# Use StandardScaler (RobustScaler doesn't support partial_fit)\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# For large datasets, fit on sample then transform in chunks\n",
    "CHUNK_SIZE = 50000\n",
    "\n",
    "if X_train.shape[0] > CHUNK_SIZE:\n",
    "    print(f\"  Fitting scaler on sample ({min(CHUNK_SIZE, X_train.shape[0])} samples) for OOM protection...\")\n",
    "    sample_indices = np.random.choice(X_train.shape[0], size=min(CHUNK_SIZE, X_train.shape[0]), replace=False)\n",
    "    scaler.fit(X_train[sample_indices])\n",
    "    del sample_indices\n",
    "    cleanup_memory()\n",
    "\n",
    "    # Transform train in chunks\n",
    "    print(f\"  Transforming train data in chunks (size={CHUNK_SIZE})...\")\n",
    "    X_train_chunks = []\n",
    "    for i in range(0, X_train.shape[0], CHUNK_SIZE):\n",
    "        chunk = scaler.transform(X_train[i:i + CHUNK_SIZE])\n",
    "        X_train_chunks.append(chunk)\n",
    "        del chunk\n",
    "        if i % (CHUNK_SIZE * 5) == 0:\n",
    "            cleanup_memory()\n",
    "    X_train = np.vstack(X_train_chunks)\n",
    "    del X_train_chunks\n",
    "    cleanup_memory()\n",
    "\n",
    "    # Transform val in chunks\n",
    "    if X_val.shape[0] > CHUNK_SIZE:\n",
    "        print(f\"  Transforming val data in chunks (size={CHUNK_SIZE})...\")\n",
    "        X_val_chunks = []\n",
    "        for i in range(0, X_val.shape[0], CHUNK_SIZE):\n",
    "            chunk = scaler.transform(X_val[i:i + CHUNK_SIZE])\n",
    "            X_val_chunks.append(chunk)\n",
    "            del chunk\n",
    "        X_val = np.vstack(X_val_chunks)\n",
    "        del X_val_chunks\n",
    "    else:\n",
    "        X_val = scaler.transform(X_val)\n",
    "else:\n",
    "    # Small dataset - fit and transform normally\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_val = scaler.transform(X_val)\n",
    "\n",
    "cleanup_memory()\n",
    "phase_time = time.time() - phase_start\n",
    "print(\"  âœ… Scaling complete!\")\n",
    "print(f\"\\nâ±ï¸  Feature Scaling Time: {phase_time:.2f} seconds ({phase_time/60:.2f} minutes)\")\n",
    "memory_usage()\n",
    "\n",
    "# Store raw (unscaled) data again for safety (if further processing needed)\n",
    "X_train_raw = X_train.copy()\n",
    "X_val_raw = X_val.copy()\n",
    "y_train_raw = y_train.copy()\n",
    "y_val_raw = y_val.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pytorch_model_header",
   "metadata": {
    "id": "pytorch_model_header",
    "papermill": {
     "duration": 0.00462,
     "end_time": "2025-11-20T00:19:09.506285",
     "exception": false,
     "start_time": "2025-11-20T00:19:09.501665",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 5. PyTorch MLP Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "pytorch_model",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-20T00:19:09.546702Z",
     "iopub.status.busy": "2025-11-20T00:19:09.546475Z",
     "iopub.status.idle": "2025-11-20T00:19:09.555516Z",
     "shell.execute_reply": "2025-11-20T00:19:09.554967Z"
    },
    "id": "pytorch_model",
    "papermill": {
     "duration": 0.042802,
     "end_time": "2025-11-20T00:19:09.561854",
     "exception": false,
     "start_time": "2025-11-20T00:19:09.519052",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    \"\"\"Enhanced Multi-Layer Perceptron with BatchNorm and Residual Connections.\"\"\"\n",
    "    def __init__(self, input_dim: int, hidden_dims: Tuple[int, ...], dropout_rate: float = 0.0, \n",
    "                 activation: str = 'relu', use_batch_norm: bool = True, use_residual: bool = False):\n",
    "        super(MLP, self).__init__()\n",
    "        \n",
    "        self.use_residual = use_residual\n",
    "        self.layers = nn.ModuleList()\n",
    "        prev_dim = input_dim\n",
    "        \n",
    "        for i, hidden_dim in enumerate(hidden_dims):\n",
    "            # Linear layer\n",
    "            self.layers.append(nn.Linear(prev_dim, hidden_dim))\n",
    "            \n",
    "            # Batch normalization\n",
    "            if use_batch_norm:\n",
    "                self.layers.append(nn.BatchNorm1d(hidden_dim))\n",
    "            \n",
    "            # Activation\n",
    "            if activation == 'relu':\n",
    "                self.layers.append(nn.ReLU())\n",
    "            elif activation == 'tanh':\n",
    "                self.layers.append(nn.Tanh())\n",
    "            elif activation == 'gelu':\n",
    "                self.layers.append(nn.GELU())\n",
    "            elif activation == 'swish':\n",
    "                self.layers.append(nn.SiLU())  # Swish/SiLU\n",
    "            else:\n",
    "                self.layers.append(nn.ReLU())\n",
    "            \n",
    "            # Dropout\n",
    "            if dropout_rate > 0:\n",
    "                self.layers.append(nn.Dropout(dropout_rate))\n",
    "            \n",
    "            prev_dim = hidden_dim\n",
    "        \n",
    "        # Output layer (with sigmoid)\n",
    "        self.output = nn.Sequential(\n",
    "            nn.Linear(prev_dim, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "        # Initialize weights\n",
    "        self._initialize_weights()\n",
    "    \n",
    "    def _initialize_weights(self):\n",
    "        \"\"\"Xavier/Glorot initialization for better convergence.\"\"\"\n",
    "        for module in self.modules():\n",
    "            if isinstance(module, nn.Linear):\n",
    "                nn.init.xavier_uniform_(module.weight)\n",
    "                if module.bias is not None:\n",
    "                    nn.init.constant_(module.bias, 0)\n",
    "            elif isinstance(module, nn.BatchNorm1d):\n",
    "                nn.init.constant_(module.weight, 1)\n",
    "                nn.init.constant_(module.bias, 0)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Store input for residual connection\n",
    "        if self.use_residual and len(self.layers) > 0:\n",
    "            residual = x\n",
    "        \n",
    "        # Forward through hidden layers\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        \n",
    "        # Residual connection (if dimensions match)\n",
    "        if self.use_residual and x.shape == residual.shape:\n",
    "            x = x + residual\n",
    "        \n",
    "        # Output layer\n",
    "        return self.output(x).squeeze()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "optuna_header",
   "metadata": {
    "id": "optuna_header",
    "papermill": {
     "duration": 0.012706,
     "end_time": "2025-11-20T00:19:09.590098",
     "exception": false,
     "start_time": "2025-11-20T00:19:09.577392",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 6. Hyperparameter Selection (Fixed Parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "optuna_setup",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-20T00:19:09.651297Z",
     "iopub.status.busy": "2025-11-20T00:19:09.651132Z",
     "iopub.status.idle": "2025-11-20T00:21:41.581190Z",
     "shell.execute_reply": "2025-11-20T00:21:41.580550Z"
    },
    "id": "optuna_setup",
    "papermill": {
     "duration": 152.002211,
     "end_time": "2025-11-20T00:21:41.608253",
     "exception": false,
     "start_time": "2025-11-20T00:19:09.606042",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "PHASE 4: Hyperparameter Selection (Fixed Parameters)\n",
      "================================================================================\n",
      "\n",
      "ðŸ“Š Using improved fixed hyperparameters:\n",
      "  Hyperparameters:\n",
      "    n_layers: 4\n",
      "    hidden_dim_base: 512\n",
      "    dim_strategy: decreasing\n",
      "    dropout_rate: 0.3\n",
      "    activation: swish\n",
      "    learning_rate: 0.0005\n",
      "    batch_size: 256\n",
      "    weight_decay: 0.001\n",
      "    use_batch_norm: True\n",
      "    use_residual: False\n",
      "    label_smoothing: 0.05\n",
      "\n",
      "ðŸ” Running quick CV validation with fixed parameters...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ Dataset too large (1080000 samples), using subset (50000 samples) for CV\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Using 50000 samples for CV validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“Š CV dataset: (50000, 1974), labels: (50000,)\n",
      "  Positive samples: 3421, Negative: 46579\n",
      "\n",
      "  Network architecture: 1974 -> [512, 256, 128, 64] -> 1\n",
      "\n",
      "  Running 5-fold CV...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1a1379bd1484bf2bf3a709cf4fc0204",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fold 1/5:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Fold 1/5: F1 = 0.4096\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "484297a7cd2c457ba4d16cd6e07a51f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fold 2/5:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Fold 2/5: F1 = 0.4059\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "434cca03640647fdae0cca6e0cf57dcd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fold 3/5:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Fold 3/5: F1 = 0.4272\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8de02b6243094109be2d45c79f0d1e41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fold 4/5:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Fold 4/5: F1 = 0.4168\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbdbe25ac89a4c50b6ab6d22a5c2bdb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fold 5/5:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Fold 5/5: F1 = 0.4436\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… CV validation complete\n",
      "  Mean CV F1: 0.4206\n",
      "  Std CV F1: 0.0136\n",
      "ðŸ’¾ Memory: 46.73 GB (RAM) | 0.04/0.05 GB (GPU used/reserved)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"PHASE 4: Hyperparameter Selection (Fixed Parameters)\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Use fixed hyperparameters (no Optuna) - IMPROVED FOR BETTER PERFORMANCE\n",
    "print(\"\\nðŸ“Š Using improved fixed hyperparameters:\")\n",
    "best_params = {\n",
    "    'n_layers': 4,  # Deeper network\n",
    "    'hidden_dim_base': 512,  # Wider network\n",
    "    'dim_strategy': 'decreasing',  # Start wide, get narrower\n",
    "    'dropout_rate': 0.3,  # More regularization\n",
    "    'activation': 'swish',  # Swish/SiLU activation (better than ReLU)\n",
    "    'learning_rate': 0.0005,  # Lower learning rate for stability\n",
    "    'batch_size': 256,  # Larger batch size\n",
    "    'weight_decay': 1e-3,  # More weight decay\n",
    "    'use_batch_norm': True,  # Batch normalization\n",
    "    'use_residual': False,  # Can enable if needed\n",
    "    'label_smoothing': 0.05,  # Label smoothing for better generalization\n",
    "}\n",
    "\n",
    "print(\"  Hyperparameters:\")\n",
    "for key, value in best_params.items():\n",
    "    print(f\"    {key}: {value}\")\n",
    "\n",
    "# Optional: Quick CV validation with fixed params\n",
    "print(\"\\nðŸ” Running quick CV validation with fixed parameters...\")\n",
    "MAX_SAMPLES_FOR_CV = 50000\n",
    "X_full = np.vstack([X_train_raw, X_val_raw])\n",
    "y_full = np.hstack([y_train_raw, y_val_raw])\n",
    "\n",
    "if len(X_full) > MAX_SAMPLES_FOR_CV:\n",
    "    print(f\"âš ï¸ Dataset too large ({len(X_full)} samples), using subset ({MAX_SAMPLES_FOR_CV} samples) for CV\")\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    X_full, _, y_full, _ = train_test_split(\n",
    "        X_full, y_full,\n",
    "        train_size=MAX_SAMPLES_FOR_CV,\n",
    "        stratify=y_full,\n",
    "        random_state=SEED\n",
    "    )\n",
    "    print(f\"  Using {len(X_full)} samples for CV validation\")\n",
    "    cleanup_memory()\n",
    "\n",
    "# Scale the CV data\n",
    "scaler_cv = StandardScaler()\n",
    "X_full_scaled = scaler_cv.fit_transform(X_full)\n",
    "\n",
    "print(f\"\\nðŸ“Š CV dataset: {X_full_scaled.shape}, labels: {y_full.shape}\")\n",
    "print(f\"  Positive samples: {y_full.sum()}, Negative: {(y_full == 0).sum()}\")\n",
    "\n",
    "# Setup Stratified K-Fold\n",
    "N_FOLDS = 5\n",
    "skf = StratifiedKFold(n_splits=N_FOLDS, shuffle=True, random_state=SEED)\n",
    "\n",
    "# Build hidden_dims\n",
    "n_layers = best_params['n_layers']\n",
    "hidden_dim_base = best_params['hidden_dim_base']\n",
    "dim_strategy = best_params['dim_strategy']\n",
    "\n",
    "hidden_dims = []\n",
    "for i in range(n_layers):\n",
    "    if dim_strategy == 'decreasing':\n",
    "        dim = hidden_dim_base // (2 ** i)\n",
    "    else:\n",
    "        dim = hidden_dim_base\n",
    "    hidden_dims.append(max(32, dim))\n",
    "\n",
    "print(f\"\\n  Network architecture: {X_full_scaled.shape[1]} -> {hidden_dims} -> 1\")\n",
    "\n",
    "# Quick CV validation\n",
    "cv_scores = []\n",
    "print(f\"\\n  Running {N_FOLDS}-fold CV...\")\n",
    "\n",
    "for fold_idx, (train_idx, val_idx) in enumerate(skf.split(X_full_scaled, y_full)):\n",
    "    X_fold_train = X_full_scaled[train_idx]\n",
    "    y_fold_train = y_full[train_idx]\n",
    "    X_fold_val = X_full_scaled[val_idx]\n",
    "    y_fold_val = y_full[val_idx]\n",
    "    \n",
    "    # Convert to tensors\n",
    "    X_train_tensor = torch.FloatTensor(X_fold_train).to(device)\n",
    "    y_train_tensor = torch.FloatTensor(y_fold_train).to(device)\n",
    "    X_val_tensor = torch.FloatTensor(X_fold_val).to(device)\n",
    "    y_val_tensor = torch.FloatTensor(y_fold_val).to(device)\n",
    "    \n",
    "    # Create model with improved architecture\n",
    "    model = MLP(\n",
    "        input_dim=X_full_scaled.shape[1],\n",
    "        hidden_dims=tuple(hidden_dims),\n",
    "        dropout_rate=best_params['dropout_rate'],\n",
    "        activation=best_params['activation'],\n",
    "        use_batch_norm=best_params.get('use_batch_norm', True),\n",
    "        use_residual=best_params.get('use_residual', False)\n",
    "    ).to(device)\n",
    "    \n",
    "    # Use AdamW optimizer (better weight decay)\n",
    "    optimizer = optim.AdamW(\n",
    "        model.parameters(), \n",
    "        lr=best_params['learning_rate'], \n",
    "        weight_decay=best_params['weight_decay'],\n",
    "        betas=(0.9, 0.999)\n",
    "    )\n",
    "    \n",
    "    # Learning rate scheduler (cosine annealing with warm restarts)\n",
    "    scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(\n",
    "        optimizer, T_0=10, T_mult=2, eta_min=1e-6\n",
    "    )\n",
    "    \n",
    "    # Calculate class weights for imbalanced data\n",
    "    pos_weight = (y_fold_train == 0).sum() / max((y_fold_train == 1).sum(), 1)\n",
    "    pos_weight_tensor = torch.tensor(pos_weight, device=device)\n",
    "    \n",
    "    # Training with improved techniques\n",
    "    model.train()\n",
    "    n_epochs = 50  # More epochs for better convergence\n",
    "    best_val_f1 = 0.0\n",
    "    patience = 10  # More patience\n",
    "    patience_counter = 0\n",
    "    \n",
    "    # Label smoothing\n",
    "    label_smoothing = best_params.get('label_smoothing', 0.0)\n",
    "    \n",
    "    # Loss function with class weights\n",
    "    criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight_tensor)\n",
    "    \n",
    "    # Progress bar for epochs\n",
    "    epoch_pbar = tqdm(range(n_epochs), desc=f\"Fold {fold_idx+1}/{N_FOLDS}\", leave=False)\n",
    "    for epoch in epoch_pbar:\n",
    "        # Mini-batch training\n",
    "        indices = torch.randperm(len(X_train_tensor), device=device)\n",
    "        batch_losses = []\n",
    "        for i in range(0, len(X_train_tensor), best_params['batch_size']):\n",
    "            batch_indices = indices[i:i + best_params['batch_size']]\n",
    "            X_batch = X_train_tensor[batch_indices]\n",
    "            y_batch = y_train_tensor[batch_indices]\n",
    "            \n",
    "            # Label smoothing\n",
    "            if label_smoothing > 0:\n",
    "                y_batch_smooth = y_batch * (1 - label_smoothing) + (1 - y_batch) * label_smoothing\n",
    "            else:\n",
    "                y_batch_smooth = y_batch\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(X_batch)\n",
    "            # Use logits for BCEWithLogitsLoss (remove sigmoid from forward if using this)\n",
    "            # For now, use regular BCE with smoothed labels\n",
    "            loss = nn.BCELoss()(outputs, y_batch_smooth)\n",
    "            loss.backward()\n",
    "            \n",
    "            # Gradient clipping for stability\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            \n",
    "            optimizer.step()\n",
    "            batch_losses.append(loss.item())\n",
    "        \n",
    "        # Learning rate scheduling\n",
    "        scheduler.step()\n",
    "        \n",
    "        # Validation\n",
    "        if (epoch + 1) % 3 == 0:  # Validate more frequently\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                val_outputs = model(X_val_tensor)\n",
    "                val_preds = (val_outputs.cpu().numpy() >= 0.5).astype(int)\n",
    "                val_f1 = f1_score(y_fold_val, val_preds)\n",
    "                \n",
    "                if val_f1 > best_val_f1:\n",
    "                    best_val_f1 = val_f1\n",
    "                    patience_counter = 0\n",
    "                else:\n",
    "                    patience_counter += 1\n",
    "                    if patience_counter >= patience:\n",
    "                        epoch_pbar.close()\n",
    "                        break\n",
    "            model.train()\n",
    "        \n",
    "        # Update progress bar\n",
    "        avg_loss = np.mean(batch_losses) if batch_losses else 0.0\n",
    "        current_lr = scheduler.get_last_lr()[0]\n",
    "        epoch_pbar.set_postfix({\n",
    "            'loss': f'{avg_loss:.4f}',\n",
    "            'val_f1': f'{best_val_f1:.4f}',\n",
    "            'lr': f'{current_lr:.2e}',\n",
    "            'patience': patience_counter\n",
    "        })\n",
    "    \n",
    "    epoch_pbar.close()\n",
    "    \n",
    "    cv_scores.append(best_val_f1)\n",
    "    print(f\"    Fold {fold_idx + 1}/{N_FOLDS}: F1 = {best_val_f1:.4f}\")\n",
    "    \n",
    "    # Cleanup\n",
    "    del model, optimizer, X_train_tensor, y_train_tensor, X_val_tensor, y_val_tensor\n",
    "    cleanup_memory()\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "best_cv_score = np.mean(cv_scores)\n",
    "print(f\"\\nâœ… CV validation complete\")\n",
    "print(f\"  Mean CV F1: {best_cv_score:.4f}\")\n",
    "print(f\"  Std CV F1: {np.std(cv_scores):.4f}\")\n",
    "\n",
    "cleanup_memory()\n",
    "memory_usage()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "optuna_study",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-20T00:21:41.646942Z",
     "iopub.status.busy": "2025-11-20T00:21:41.646640Z",
     "iopub.status.idle": "2025-11-20T00:21:41.893318Z",
     "shell.execute_reply": "2025-11-20T00:21:41.892550Z"
    },
    "id": "optuna_study",
    "papermill": {
     "duration": 0.263843,
     "end_time": "2025-11-20T00:21:41.893840",
     "exception": false,
     "start_time": "2025-11-20T00:21:41.629997",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Run Optuna study (if enabled) or use default hyperparameters\n",
    "USE_OPTUNA = False\n",
    "if USE_OPTUNA:\n",
    "    try:\n",
    "        study = optuna.create_study(\n",
    "            direction='maximize',\n",
    "            sampler=TPESampler(seed=SEED)\n",
    "        )\n",
    "\n",
    "        print(\"\\nðŸš€ Starting Optuna optimization...\")\n",
    "        start_time = time.time()\n",
    "\n",
    "        study.optimize(\n",
    "            objective,\n",
    "            n_trials=N_TRIALS,\n",
    "            timeout=TIMEOUT_SECONDS,\n",
    "            show_progress_bar=True\n",
    "        )\n",
    "\n",
    "        elapsed_time = time.time() - start_time\n",
    "\n",
    "        best_params = study.best_params\n",
    "        best_cv_score = study.best_value\n",
    "\n",
    "        print(f\"\\nâœ… Optuna optimization complete ({elapsed_time/60:.1f} min)\")\n",
    "        print(f\"  Best CV F1: {best_cv_score:.4f}\")\n",
    "        print(f\"  Best parameters:\")\n",
    "        for key, value in best_params.items():\n",
    "            print(f\"    {key}: {value}\")\n",
    "\n",
    "        cleanup_memory()\n",
    "        memory_usage()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error in Optuna optimization: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        best_params = {}\n",
    "        best_cv_score = 0.0\n",
    "cleanup_memory()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "final_training_header",
   "metadata": {
    "id": "final_training_header",
    "papermill": {
     "duration": 0.005494,
     "end_time": "2025-11-20T00:21:41.905387",
     "exception": false,
     "start_time": "2025-11-20T00:21:41.899893",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 7. Final Model Training & Threshold Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "final_training",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-20T00:21:41.942279Z",
     "iopub.status.busy": "2025-11-20T00:21:41.942078Z",
     "iopub.status.idle": "2025-11-20T00:27:26.213230Z",
     "shell.execute_reply": "2025-11-20T00:27:26.212602Z"
    },
    "id": "final_training",
    "papermill": {
     "duration": 344.300916,
     "end_time": "2025-11-20T00:27:26.213961",
     "exception": false,
     "start_time": "2025-11-20T00:21:41.913045",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "PHASE 5: Final Model Training & Threshold Tuning\n",
      "================================================================================\n",
      "Training Final Model on Full Dataset...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Training for up to 150 epochs with early stopping (patience=20)...\n",
      "  Using class weight: 13.59, label smoothing: 0.05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db376451c5e744fa9025e2979b61117b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/150 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Early stopping at epoch 33\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… Final Optimal Threshold: 0.1949\n",
      "âœ… Final Validation F1: 0.5131\n",
      "\n",
      "â±ï¸  Final Model Training & Threshold Tuning Time: 343.87 seconds (5.73 minutes)\n",
      "\n",
      "ðŸ“Š Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9707    0.9457    0.9581    111925\n",
      "           1     0.4456    0.6047    0.5131      8075\n",
      "\n",
      "    accuracy                         0.9228    120000\n",
      "   macro avg     0.7081    0.7752    0.7356    120000\n",
      "weighted avg     0.9354    0.9228    0.9281    120000\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ’¾ Memory: 46.89 GB (RAM) | 7.99/8.01 GB (GPU used/reserved)\n"
     ]
    }
   ],
   "source": [
    "# Train final model on full data\n",
    "try:\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"PHASE 5: Final Model Training & Threshold Tuning\")\n",
    "    print(\"=\" * 80)\n",
    "    phase_start = time.time()\n",
    "    print(\"Training Final Model on Full Dataset...\")\n",
    "\n",
    "    # Use best parameters from Optuna or improved defaults\n",
    "    if 'best_params' not in locals() or not best_params:\n",
    "        print(\"  âš ï¸ best_params not found, using improved defaults\")\n",
    "        best_params = {\n",
    "            'n_layers': 4,\n",
    "            'hidden_dim_base': 512,\n",
    "            'dim_strategy': 'decreasing',\n",
    "            'dropout_rate': 0.3,\n",
    "            'activation': 'swish',\n",
    "            'learning_rate': 0.0005,\n",
    "            'batch_size': 256,\n",
    "            'weight_decay': 1e-3,\n",
    "            'use_batch_norm': True,\n",
    "            'use_residual': False,\n",
    "            'label_smoothing': 0.05\n",
    "        }\n",
    "        best_cv_score = 0.0\n",
    "\n",
    "    # Build hidden_dims from best_params\n",
    "    n_layers = best_params.get('n_layers', 3)\n",
    "    hidden_dim_base = best_params.get('hidden_dim_base', 256)\n",
    "    dim_strategy = best_params.get('dim_strategy', 'decreasing')\n",
    "    \n",
    "    hidden_dims = []\n",
    "    for i in range(n_layers):\n",
    "        if dim_strategy == 'decreasing':\n",
    "            dim = hidden_dim_base // (2 ** i)\n",
    "        else:\n",
    "            dim = hidden_dim_base\n",
    "        hidden_dims.append(max(32, dim))\n",
    "\n",
    "    # Create final model with improved architecture\n",
    "    final_model = MLP(\n",
    "        input_dim=X_train.shape[1],\n",
    "        hidden_dims=tuple(hidden_dims),\n",
    "        dropout_rate=best_params.get('dropout_rate', 0.3),\n",
    "        activation=best_params.get('activation', 'swish'),\n",
    "        use_batch_norm=best_params.get('use_batch_norm', True),\n",
    "        use_residual=best_params.get('use_residual', False)\n",
    "    ).to(device)\n",
    "\n",
    "    # Use AdamW optimizer with improved settings\n",
    "    optimizer = optim.AdamW(\n",
    "        final_model.parameters(), \n",
    "        lr=best_params.get('learning_rate', 0.0005), \n",
    "        weight_decay=best_params.get('weight_decay', 1e-3),\n",
    "        betas=(0.9, 0.999)\n",
    "    )\n",
    "    \n",
    "    # Learning rate scheduler\n",
    "    scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(\n",
    "        optimizer, T_0=15, T_mult=2, eta_min=1e-6\n",
    "    )\n",
    "    \n",
    "    # Calculate class weights\n",
    "    pos_weight = (y_train == 0).sum() / max((y_train == 1).sum(), 1)\n",
    "    pos_weight_tensor = torch.tensor(pos_weight, device=device)\n",
    "    \n",
    "    batch_size = best_params.get('batch_size', 256)\n",
    "    label_smoothing = best_params.get('label_smoothing', 0.05)\n",
    "    X_train_tensor = torch.FloatTensor(X_train).to(device)\n",
    "    y_train_tensor = torch.FloatTensor(y_train).to(device)\n",
    "    X_val_tensor = torch.FloatTensor(X_val).to(device)\n",
    "    y_val_tensor = torch.FloatTensor(y_val).to(device)\n",
    "\n",
    "    final_model.train()\n",
    "    n_epochs = 150  # More epochs\n",
    "    best_val_f1 = 0.0\n",
    "    patience = 20  # More patience\n",
    "    patience_counter = 0\n",
    "\n",
    "    print(f\"  Training for up to {n_epochs} epochs with early stopping (patience={patience})...\")\n",
    "    print(f\"  Using class weight: {pos_weight:.2f}, label smoothing: {label_smoothing}\")\n",
    "\n",
    "    # Progress bar for epochs\n",
    "    epoch_pbar = tqdm(range(n_epochs), desc=\"Training\", unit=\"epoch\")\n",
    "    for epoch in epoch_pbar:\n",
    "        # Mini-batch training\n",
    "        indices = torch.randperm(len(X_train_tensor), device=device)\n",
    "        batch_losses = []\n",
    "        for i in range(0, len(X_train_tensor), batch_size):\n",
    "            batch_indices = indices[i:i + batch_size]\n",
    "            X_batch = X_train_tensor[batch_indices]\n",
    "            y_batch = y_train_tensor[batch_indices]\n",
    "            \n",
    "            # Label smoothing\n",
    "            if label_smoothing > 0:\n",
    "                y_batch_smooth = y_batch * (1 - label_smoothing) + (1 - y_batch) * label_smoothing\n",
    "            else:\n",
    "                y_batch_smooth = y_batch\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = final_model(X_batch)\n",
    "            loss = nn.BCELoss()(outputs, y_batch_smooth)\n",
    "            loss.backward()\n",
    "            \n",
    "            # Gradient clipping\n",
    "            torch.nn.utils.clip_grad_norm_(final_model.parameters(), max_norm=1.0)\n",
    "            \n",
    "            optimizer.step()\n",
    "            batch_losses.append(loss.item())\n",
    "        \n",
    "        # Learning rate scheduling\n",
    "        scheduler.step()\n",
    "        \n",
    "        # Validation every epoch\n",
    "        final_model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_outputs = final_model(X_val_tensor)\n",
    "            val_proba = val_outputs.cpu().numpy()\n",
    "            val_preds = (val_proba >= 0.5).astype(int)\n",
    "            val_f1 = f1_score(y_val, val_preds)\n",
    "            \n",
    "            if val_f1 > best_val_f1:\n",
    "                best_val_f1 = val_f1\n",
    "                patience_counter = 0\n",
    "                # Save best model state\n",
    "                best_model_state = final_model.state_dict().copy()\n",
    "            else:\n",
    "                patience_counter += 1\n",
    "                if patience_counter >= patience:\n",
    "                    epoch_pbar.set_description(f\"Early stopping at epoch {epoch + 1}\")\n",
    "                    epoch_pbar.close()\n",
    "                    print(f\"\\n  Early stopping at epoch {epoch + 1}\")\n",
    "                    break\n",
    "        \n",
    "        final_model.train()\n",
    "        \n",
    "        # Update progress bar\n",
    "        avg_loss = np.mean(batch_losses) if batch_losses else 0.0\n",
    "        current_lr = scheduler.get_last_lr()[0]\n",
    "        epoch_pbar.set_postfix({\n",
    "            'loss': f'{avg_loss:.4f}',\n",
    "            'val_f1': f'{val_f1:.4f}',\n",
    "            'best_f1': f'{best_val_f1:.4f}',\n",
    "            'lr': f'{current_lr:.2e}',\n",
    "            'patience': f'{patience_counter}/{patience}'\n",
    "        })\n",
    "    \n",
    "    epoch_pbar.close()\n",
    "\n",
    "    # Load best model state\n",
    "    if 'best_model_state' in locals():\n",
    "        final_model.load_state_dict(best_model_state)\n",
    "\n",
    "    # Get predictions on validation set\n",
    "    final_model.eval()\n",
    "    with torch.no_grad():\n",
    "        y_val_proba = final_model(X_val_tensor).cpu().numpy()\n",
    "\n",
    "    # Find optimal threshold\n",
    "    precision, recall, pr_thresholds = precision_recall_curve(y_val, y_val_proba)\n",
    "    f1_scores_pr = 2 * (precision * recall) / (precision + recall + 1e-10)\n",
    "    best_pr_idx = np.argmax(f1_scores_pr)\n",
    "    best_pr_threshold = pr_thresholds[best_pr_idx] if best_pr_idx < len(pr_thresholds) else 0.5\n",
    "    best_pr_f1 = f1_scores_pr[best_pr_idx]\n",
    "\n",
    "    # Manual fine-grained search\n",
    "    thresholds = np.concatenate([\n",
    "        np.linspace(0.01, 0.05, 20),\n",
    "        np.linspace(0.05, 0.15, 50),\n",
    "        np.linspace(0.15, 0.3, 30),\n",
    "        np.linspace(0.3, 0.9, 20)\n",
    "    ])\n",
    "\n",
    "    best_threshold = best_pr_threshold\n",
    "    best_f1 = best_pr_f1\n",
    "    for thr in thresholds:\n",
    "        y_pred = (y_val_proba >= thr).astype(int)\n",
    "        f1 = f1_score(y_val, y_pred, pos_label=1, zero_division=0)\n",
    "        if f1 > best_f1:\n",
    "            best_f1 = f1\n",
    "            best_threshold = thr\n",
    "\n",
    "    phase_time = time.time() - phase_start\n",
    "    print(f\"\\nâœ… Final Optimal Threshold: {best_threshold:.4f}\")\n",
    "    print(f\"âœ… Final Validation F1: {best_f1:.4f}\")\n",
    "    print(f\"\\nâ±ï¸  Final Model Training & Threshold Tuning Time: {phase_time:.2f} seconds ({phase_time/60:.2f} minutes)\")\n",
    "\n",
    "    # Classification report\n",
    "    y_val_pred = (y_val_proba >= best_threshold).astype(int)\n",
    "    print(\"\\nðŸ“Š Classification Report:\")\n",
    "    print(classification_report(y_val, y_val_pred, digits=4, zero_division=0))\n",
    "\n",
    "    cleanup_memory()\n",
    "    memory_usage()\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"âŒ Error in final training: {e}\")\n",
    "    raise\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "save_model_header",
   "metadata": {
    "id": "save_model_header",
    "papermill": {
     "duration": 0.006076,
     "end_time": "2025-11-20T00:27:26.259530",
     "exception": false,
     "start_time": "2025-11-20T00:27:26.253454",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 8. Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "save_model",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-20T00:27:26.272359Z",
     "iopub.status.busy": "2025-11-20T00:27:26.272173Z",
     "iopub.status.idle": "2025-11-20T00:27:26.347233Z",
     "shell.execute_reply": "2025-11-20T00:27:26.346646Z"
    },
    "id": "save_model",
    "papermill": {
     "duration": 0.082119,
     "end_time": "2025-11-20T00:27:26.347751",
     "exception": false,
     "start_time": "2025-11-20T00:27:26.265632",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ’¾ Model saved to: /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/Kaggle_2/models/saved_models/model_pytorch_mlp_all_features_best.pkl\n"
     ]
    }
   ],
   "source": [
    "# Save model\n",
    "try:\n",
    "    model_save_path = MODEL_SAVE_DIR / \"model_pytorch_mlp_all_features_best.pkl\"\n",
    "\n",
    "    save_dict = {\n",
    "        \"model_state_dict\": final_model.state_dict(),\n",
    "        \"model_config\": {\n",
    "            \"input_dim\": X_train.shape[1],\n",
    "            \"hidden_dims\": hidden_dims,\n",
    "            \"dropout_rate\": best_params.get('dropout_rate', 0.2),\n",
    "            \"activation\": best_params.get('activation', 'relu')\n",
    "        },\n",
    "        \"scaler\": scaler,\n",
    "        \"best_params\": best_params,\n",
    "        \"best_cv_score\": best_cv_score,\n",
    "        \"best_threshold\": best_threshold,\n",
    "        \"best_f1\": best_f1,\n",
    "        \"reg_cols\": reg_cols,\n",
    "        \"emb_family_to_cols\": emb_family_to_cols,\n",
    "    }\n",
    "\n",
    "    with open(model_save_path, \"wb\") as f:\n",
    "        pickle.dump(save_dict, f)\n",
    "\n",
    "    print(f\"\\nðŸ’¾ Model saved to: {model_save_path}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"âŒ Error saving model: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "submission_header",
   "metadata": {
    "id": "submission_header",
    "papermill": {
     "duration": 0.006053,
     "end_time": "2025-11-20T00:27:26.360391",
     "exception": false,
     "start_time": "2025-11-20T00:27:26.354338",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 9. Generate Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "submission",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-20T00:27:26.415989Z",
     "iopub.status.busy": "2025-11-20T00:27:26.415807Z",
     "iopub.status.idle": "2025-11-20T00:27:44.672047Z",
     "shell.execute_reply": "2025-11-20T00:27:44.671412Z"
    },
    "id": "submission",
    "papermill": {
     "duration": 18.32673,
     "end_time": "2025-11-20T00:27:44.693139",
     "exception": false,
     "start_time": "2025-11-20T00:27:26.366409",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "PHASE 6: Test Predictions\n",
      "================================================================================\n",
      "Generating Test Predictions...\n",
      "Loading test from /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/Kaggle_2/data/model_ready/test_model_ready.parquet\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… Submission saved to: /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/Kaggle_2/data/submission_files/submission_model_pytorch_mlp.csv\n",
      "  Test predictions: 120000, Positive: 10735, Negative: 109265\n",
      "\n",
      "â±ï¸  Test Predictions Time: 17.98 seconds (0.30 minutes)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ’¾ Memory: 51.82 GB (RAM) | 7.99/8.01 GB (GPU used/reserved)\n",
      "\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "MODEL_PYTORCH_MLP EXECUTION COMPLETED\n",
      "Start Time: 2025-11-19 19:15:22\n",
      "End Time: 2025-11-19 19:27:44\n",
      "Total Execution Time: 741.76 seconds (12.36 minutes / 0.21 hours)\n",
      "Final Validation F1 Score: 0.5131\n",
      "================================================================================\n",
      "\n",
      "End Time: 2025-11-19 19:27:44\n",
      "Final Validation F1 Score: 0.5131\n",
      "================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def extract_work_id(id_value: str) -> str:\n",
    "    \"\"\"Extract work_id from URL or return as is if already just ID.\"\"\"\n",
    "    id_str = str(id_value)\n",
    "    # If it already looks like a work ID, just return it\n",
    "    if id_str.startswith('W') and len(id_str) > 1 and '/' not in id_str:\n",
    "        return id_str\n",
    "    # Otherwise, extract from URL or string\n",
    "    match = re.search(r'W\\d+', id_str)\n",
    "    if match:\n",
    "        return match.group(0)\n",
    "    return id_str\n",
    "\n",
    "# Load test data and generate predictions\n",
    "try:\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"PHASE 6: Test Predictions\")\n",
    "    print(\"=\" * 80)\n",
    "    phase_start = time.time()\n",
    "    print(\"Generating Test Predictions...\")\n",
    "\n",
    "    test_df = load_parquet_split(\"test\")\n",
    "    test_ids = test_df[\"id\"].to_numpy()\n",
    "\n",
    "    # Process test data same as train\n",
    "    X_reg_test, X_emb_test_fams, _, _, _ = split_features_reg_and_all_emb(test_df)\n",
    "    del test_df\n",
    "\n",
    "    # Combine embeddings (NO PCA)\n",
    "    X_emb_test_list = []\n",
    "    for fam in X_emb_test_fams.keys():\n",
    "        X_emb_test_list.append(X_emb_test_fams[fam])\n",
    "    X_emb_test = np.hstack(X_emb_test_list) if X_emb_test_list else None\n",
    "\n",
    "    if X_reg_test is not None:\n",
    "        X_test = np.hstack([X_reg_test, X_emb_test]) if X_emb_test is not None else X_reg_test\n",
    "    else:\n",
    "        X_test = X_emb_test\n",
    "\n",
    "    del X_reg_test, X_emb_test_fams, X_emb_test_list, X_emb_test\n",
    "    cleanup_memory()\n",
    "\n",
    "    # Scale\n",
    "    if \"scaler\" in locals():\n",
    "        X_test = scaler.transform(X_test)\n",
    "\n",
    "    # Predict in chunks\n",
    "    chunk_size = 10000\n",
    "    final_model.eval()\n",
    "    y_test_proba_chunks = []\n",
    "    \n",
    "    for i in range(0, X_test.shape[0], chunk_size):\n",
    "        X_test_chunk = torch.FloatTensor(X_test[i:i + chunk_size]).to(device)\n",
    "        with torch.no_grad():\n",
    "            chunk_proba = final_model(X_test_chunk).cpu().numpy()\n",
    "        y_test_proba_chunks.append(chunk_proba)\n",
    "        del X_test_chunk\n",
    "        cleanup_memory()\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "    \n",
    "    y_test_proba = np.concatenate(y_test_proba_chunks)\n",
    "    del y_test_proba_chunks\n",
    "\n",
    "    y_test_pred = (y_test_proba >= best_threshold).astype(int)\n",
    "\n",
    "    # Create submission using Polars\n",
    "    work_ids = np.array([extract_work_id(str(id_val)) for id_val in test_ids])\n",
    "    submission_df = pl.DataFrame({\"work_id\": work_ids, \"label\": y_test_pred})\n",
    "\n",
    "    submission_path = SUBMISSION_DIR / \"submission_model_pytorch_mlp.csv\"\n",
    "    submission_df.write_csv(submission_path)\n",
    "\n",
    "    phase_time = time.time() - phase_start\n",
    "    print(f\"\\nâœ… Submission saved to: {submission_path}\")\n",
    "    print(f\"  Test predictions: {len(y_test_pred)}, Positive: {y_test_pred.sum()}, Negative: {(y_test_pred==0).sum()}\")\n",
    "    print(f\"\\nâ±ï¸  Test Predictions Time: {phase_time:.2f} seconds ({phase_time/60:.2f} minutes)\")\n",
    "\n",
    "    cleanup_memory()\n",
    "    memory_usage()\n",
    "    \n",
    "    # Print total execution time summary\n",
    "    total_time = time.time() - TOTAL_START_TIME\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    # Print total execution time summary\n",
    "    total_time = time.time() - TOTAL_START_TIME\n",
    "    END_TIME_STR = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"MODEL_PYTORCH_MLP EXECUTION COMPLETED\")\n",
    "    print(f\"Start Time: {START_TIME_STR}\")\n",
    "    print(f\"End Time: {END_TIME_STR}\")\n",
    "    print(f\"Total Execution Time: {total_time:.2f} seconds ({total_time/60:.2f} minutes / {total_time/3600:.2f} hours)\")\n",
    "    print(f\"Final Validation F1 Score: {best_f1:.4f}\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "    print(f\"End Time: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "    print(f\"Final Validation F1 Score: {best_f1:.4f}\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "\n",
    "except Exception as e:\n",
    "    total_time = time.time() - TOTAL_START_TIME\n",
    "    print(f\"\\nâŒ Error generating submission: {e}\")\n",
    "    print(f\"Execution failed after {total_time:.2f} seconds ({total_time/60:.2f} minutes)\")\n",
    "    raise\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 770.017458,
   "end_time": "2025-11-20T00:27:52.524251",
   "environment_variables": {},
   "exception": null,
   "input_path": "src/notebooks/model_pytorch_mlp_all_features.ipynb",
   "output_path": "/scratch/si670f25_class_root/si670f25_class/santoshd/Kaggle_2/runs/model_pytorch_mlp_executed_20251119-191454.ipynb",
   "parameters": {},
   "start_time": "2025-11-20T00:15:02.506793",
   "version": "2.6.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "01b8e069f6ef43eab0485f2f646ea310": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "043d735fe11f485b9d4b59f6c540efba": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_d8a399b3ca2246fa8ce60cbd1c3699a4",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_1ec4c39709d8405a83d9a4975ef5c070",
       "tabbable": null,
       "tooltip": null,
       "value": "â€‡41/50â€‡[00:18&lt;00:03,â€‡â€‡2.34it/s,â€‡loss=0.2152,â€‡val_f1=0.4059,â€‡lr=4.13e-04,â€‡patience=9]"
      }
     },
     "0c1c01e7a742410ebefc8fc997f034af": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "0d56820d446648bbaee096a97b156599": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "0dda00619df242a8895816fb9fbc7f27": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_1f00ecdb8ec8415ca9e361507df7e06b",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_851ff6a64ca74236812532c7227b86cc",
       "tabbable": null,
       "tooltip": null,
       "value": "Earlyâ€‡stoppingâ€‡atâ€‡epochâ€‡33:â€‡â€‡21%"
      }
     },
     "0de6799906a24694906572e89f93fee7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_6dc52c7f4d7b4aac9ccb09932e95fbe2",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_5d62f55495bf460080740649927ac5bd",
       "tabbable": null,
       "tooltip": null,
       "value": "Foldâ€‡5/5:â€‡â€‡94%"
      }
     },
     "184d420878014d16b55834eeeaef5bb2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "1a9a6c269d6f46abb42a76aa4760ac7d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "danger",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_4e65add3c6d7458489cbfb5cb63e020d",
       "max": 50.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_35090438301c482ea7a22a6fd97e8495",
       "tabbable": null,
       "tooltip": null,
       "value": 32.0
      }
     },
     "1ec4c39709d8405a83d9a4975ef5c070": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "1f00ecdb8ec8415ca9e361507df7e06b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "210e148e7ebb420ab0f0666b47ebd19f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "264b865e5477473597d1cfe3d79a23b6": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "28806371271c4969a379dbd45fb6b0fd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_ccd354a976284bb6992cf539d07a4adb",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_63c65e83574e4e2a98dfe5e6b4a1aeda",
       "tabbable": null,
       "tooltip": null,
       "value": "Foldâ€‡2/5:â€‡â€‡82%"
      }
     },
     "291e15ee16e54dd5827f83acf5c0684c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "2ebb45b2e15f41f5854fe28d19ee5d35": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "2fd33553df5c4fa2b920f53567c13afc": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "35090438301c482ea7a22a6fd97e8495": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "3a9a69c566684eafb44fb41e145cd6bf": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "danger",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_f0e76577aa654f71a0ca9589ad3dfc10",
       "max": 150.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_6fff21498b0240839f542553af58563d",
       "tabbable": null,
       "tooltip": null,
       "value": 32.0
      }
     },
     "3fd1cd8a6d474b4cad86ebd3b16327d7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "danger",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_d0d14e51eb8e468897e925d4ed4eb2a4",
       "max": 50.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_aecb002be2fe42819cdaabc4f8527263",
       "tabbable": null,
       "tooltip": null,
       "value": 38.0
      }
     },
     "415e48d556114dc493995c266ecedc7d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_c49fc1394ee34fdf8298b0114dcbbdb1",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_fee2a0318f7f444cb1080071e12bd961",
       "tabbable": null,
       "tooltip": null,
       "value": "â€‡47/50â€‡[00:20&lt;00:01,â€‡â€‡2.38it/s,â€‡loss=0.2115,â€‡val_f1=0.4436,â€‡lr=3.09e-04,â€‡patience=9]"
      }
     },
     "42f6d525915d4a5bbdb318e963b7503e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "434cca03640647fdae0cca6e0cf57dcd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_551a2d71bbc443648737d9ec9ddfcd28",
        "IPY_MODEL_1a9a6c269d6f46abb42a76aa4760ac7d",
        "IPY_MODEL_5e35af14d8f64f9d9598edcbfa933c09"
       ],
       "layout": "IPY_MODEL_5f50cd10fa6a45b2befa45905c6ad1c2",
       "tabbable": null,
       "tooltip": null
      }
     },
     "484297a7cd2c457ba4d16cd6e07a51f6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_28806371271c4969a379dbd45fb6b0fd",
        "IPY_MODEL_732542b581534c5d952830edaa3776c2",
        "IPY_MODEL_043d735fe11f485b9d4b59f6c540efba"
       ],
       "layout": "IPY_MODEL_2ebb45b2e15f41f5854fe28d19ee5d35",
       "tabbable": null,
       "tooltip": null
      }
     },
     "4e65add3c6d7458489cbfb5cb63e020d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "50b78ae6a5f546d6b599d4407fdbe04c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "52dd017742e042d8a09aed57a3d9690e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "551a2d71bbc443648737d9ec9ddfcd28": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_50b78ae6a5f546d6b599d4407fdbe04c",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_6260855dba1a4232a62900913bc14ea6",
       "tabbable": null,
       "tooltip": null,
       "value": "Foldâ€‡3/5:â€‡â€‡64%"
      }
     },
     "5d62f55495bf460080740649927ac5bd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "5e35af14d8f64f9d9598edcbfa933c09": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_61e71edf8d5547cea9c57d246728e8fe",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_42f6d525915d4a5bbdb318e963b7503e",
       "tabbable": null,
       "tooltip": null,
       "value": "â€‡32/50â€‡[00:14&lt;00:07,â€‡â€‡2.34it/s,â€‡loss=0.2404,â€‡val_f1=0.4272,â€‡lr=4.97e-04,â€‡patience=9]"
      }
     },
     "5f50cd10fa6a45b2befa45905c6ad1c2": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "601eeb0f09224ac0b07070c3aab90eef": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "61e71edf8d5547cea9c57d246728e8fe": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "6260855dba1a4232a62900913bc14ea6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "63c65e83574e4e2a98dfe5e6b4a1aeda": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "6dc52c7f4d7b4aac9ccb09932e95fbe2": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "6fff21498b0240839f542553af58563d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "708cd5733c4f4ae297aa35e9fd2ce72e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_0c1c01e7a742410ebefc8fc997f034af",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_cc5f1d1447e440de8bf101b58b7163f3",
       "tabbable": null,
       "tooltip": null,
       "value": "Foldâ€‡1/5:â€‡â€‡76%"
      }
     },
     "71b812d70e19488fa13f5212b2ad2c15": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "732542b581534c5d952830edaa3776c2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "danger",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_2fd33553df5c4fa2b920f53567c13afc",
       "max": 50.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_ad599cb5352243bbaacb4a5fd263458d",
       "tabbable": null,
       "tooltip": null,
       "value": 41.0
      }
     },
     "7390b44adc5143368e520b3ee24a47d8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "danger",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_264b865e5477473597d1cfe3d79a23b6",
       "max": 50.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_52dd017742e042d8a09aed57a3d9690e",
       "tabbable": null,
       "tooltip": null,
       "value": 47.0
      }
     },
     "7654f2a97c02449f8bd07aada4fb2461": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_01b8e069f6ef43eab0485f2f646ea310",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_601eeb0f09224ac0b07070c3aab90eef",
       "tabbable": null,
       "tooltip": null,
       "value": "â€‡38/50â€‡[00:23&lt;00:05,â€‡â€‡2.39it/s,â€‡loss=0.2209,â€‡val_f1=0.4096,â€‡lr=4.52e-04,â€‡patience=9]"
      }
     },
     "851ff6a64ca74236812532c7227b86cc": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "8cffe14133e64c2e9efd10e2e8154e9d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_f52b5e5f4b3248608e780c965a9bba33",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_cb87362b2e654590b1dbced0e2193f6a",
       "tabbable": null,
       "tooltip": null,
       "value": "â€‡32/150â€‡[05:36&lt;19:55,â€‡10.13s/epoch,â€‡loss=0.2541,â€‡val_f1=0.4781,â€‡best_f1=0.4901,â€‡lr=1.99e-04,â€‡patience=19/20]"
      }
     },
     "8de02b6243094109be2d45c79f0d1e41": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_92d31da57cc342e695632d989ad5e178",
        "IPY_MODEL_e6fae860a0f04524abb48e9065f97c61",
        "IPY_MODEL_b8e479a2c92c4f31ac52463cbcf68bc6"
       ],
       "layout": "IPY_MODEL_e854be3059bb4b48b27462f378bc1585",
       "tabbable": null,
       "tooltip": null
      }
     },
     "92d31da57cc342e695632d989ad5e178": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_0d56820d446648bbaee096a97b156599",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_210e148e7ebb420ab0f0666b47ebd19f",
       "tabbable": null,
       "tooltip": null,
       "value": "Foldâ€‡4/5:â€‡â€‡76%"
      }
     },
     "9d97f7fca10d443886b3fa9c241da8db": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "a97e35f9c67f45f2a7a6d9973a672051": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "ad599cb5352243bbaacb4a5fd263458d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "aecb002be2fe42819cdaabc4f8527263": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "b8e479a2c92c4f31ac52463cbcf68bc6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_a97e35f9c67f45f2a7a6d9973a672051",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_71b812d70e19488fa13f5212b2ad2c15",
       "tabbable": null,
       "tooltip": null,
       "value": "â€‡38/50â€‡[00:16&lt;00:05,â€‡â€‡2.37it/s,â€‡loss=0.2227,â€‡val_f1=0.4168,â€‡lr=4.52e-04,â€‡patience=9]"
      }
     },
     "bd519f8edb064d91842755338752b6bc": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "c49fc1394ee34fdf8298b0114dcbbdb1": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "cb87362b2e654590b1dbced0e2193f6a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "cbdbe25ac89a4c50b6ab6d22a5c2bdb0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_0de6799906a24694906572e89f93fee7",
        "IPY_MODEL_7390b44adc5143368e520b3ee24a47d8",
        "IPY_MODEL_415e48d556114dc493995c266ecedc7d"
       ],
       "layout": "IPY_MODEL_9d97f7fca10d443886b3fa9c241da8db",
       "tabbable": null,
       "tooltip": null
      }
     },
     "cc5f1d1447e440de8bf101b58b7163f3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "ccd354a976284bb6992cf539d07a4adb": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "ccf6212df7924365862fe5975b7fd7eb": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d0d14e51eb8e468897e925d4ed4eb2a4": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d8a399b3ca2246fa8ce60cbd1c3699a4": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "db376451c5e744fa9025e2979b61117b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_0dda00619df242a8895816fb9fbc7f27",
        "IPY_MODEL_3a9a69c566684eafb44fb41e145cd6bf",
        "IPY_MODEL_8cffe14133e64c2e9efd10e2e8154e9d"
       ],
       "layout": "IPY_MODEL_bd519f8edb064d91842755338752b6bc",
       "tabbable": null,
       "tooltip": null
      }
     },
     "e6fae860a0f04524abb48e9065f97c61": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "danger",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_ccf6212df7924365862fe5975b7fd7eb",
       "max": 50.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_184d420878014d16b55834eeeaef5bb2",
       "tabbable": null,
       "tooltip": null,
       "value": 38.0
      }
     },
     "e854be3059bb4b48b27462f378bc1585": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f0e76577aa654f71a0ca9589ad3dfc10": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f1a1379bd1484bf2bf3a709cf4fc0204": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_708cd5733c4f4ae297aa35e9fd2ce72e",
        "IPY_MODEL_3fd1cd8a6d474b4cad86ebd3b16327d7",
        "IPY_MODEL_7654f2a97c02449f8bd07aada4fb2461"
       ],
       "layout": "IPY_MODEL_291e15ee16e54dd5827f83acf5c0684c",
       "tabbable": null,
       "tooltip": null
      }
     },
     "f52b5e5f4b3248608e780c965a9bba33": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "fee2a0318f7f444cb1080071e12bd961": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}