Activating virtual environment: /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/Kaggle_2/venv
==========================================
JOB STARTUP INFORMATION
==========================================
Host:        gl1005.arc-ts.umich.edu
Date:        2025-11-17T02:22:13-05:00
SLURM_JOBID: 36116803
CUDA_HOME:   /sw/pkgs/arc/cuda/12.1.1
Working directory: /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/Kaggle_2
Python:      /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/Kaggle_2/venv/bin/python

=== GPU Information ===
Mon Nov 17 02:22:13 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 570.124.06             Driver Version: 570.124.06     CUDA Version: 12.8     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  Tesla V100-PCIE-16GB           On  |   00000000:D8:00.0 Off |                    0 |
| N/A   31C    P0             25W /  250W |       1MiB /  16384MiB |      0%   E. Process |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|  No running processes found                                                             |
+-----------------------------------------------------------------------------------------+
==========================================

=== Verifying environment ===
Verifying Python environment...
âœ“ Basic packages available
âœ“ Python environment verified
Downloading spaCy model (if needed, max 5 minutes)...
Collecting en-core-web-sm==3.8.0
  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)
     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 12.8/12.8 MB 57.0 MB/s  0:00:00
[38;5;2mâœ” Download and installation successful[0m
You can now load the package via spacy.load('en_core_web_sm')
timeout: the monitored command dumped core
âš  spaCy model download failed or timed out (will skip NER features)
   This is not critical - NER features are optional
Installing Jupyter kernel: data-explore-36116803...
Installed kernelspec data-explore-36116803 in /home/santoshd/.local/share/jupyter/kernels/data-explore-36116803
âœ“ Kernel installed successfully
Running pre-flight validation...
âœ“ Found data files in data/processed/ directory
âœ“ Notebook found: src/notebooks/data_exploration_organized.ipynb
âœ“ Models directory found (optional)
âœ… Pre-flight validation passed!

Resource monitoring started (PID: 1864758)
Monitor log: /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/Kaggle_2/logs/resource_monitor.log

=== Killing Previous Notebook Instances ===
=== Killing Previous Notebook Instances ===

1. Checking for papermill processes...
  âœ“ No papermill processes found

2. Checking for jupyter notebook processes...
  âœ“ No jupyter notebook processes found

3. Checking for jupyter lab processes...
  âœ“ No jupyter lab processes found

4. Checking for ipykernel processes...
  âœ“ No ipykernel processes found

5. Checking for Python processes running notebooks...
  âœ“ No Python notebook processes found

6. Cleaning up stale kernel connections...

âœ“ No previous notebook instances found - ready for clean execution

=== Cleanup Complete ===

Running papermill -> /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/Kaggle_2/runs/data_exploration_executed_20251117-022344.ipynb
Input Notebook:  src/notebooks/data_exploration_organized.ipynb
Output Notebook: /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/Kaggle_2/runs/data_exploration_executed_20251117-022344.ipynb
Executing:   0%|          | 0/30 [00:00<?, ?cell/s]Executing notebook with kernel: data-explore-36116803
Executing:   3%|â–Ž         | 1/30 [00:07<03:33,  7.36s/cell]Executing:  10%|â–ˆ         | 3/30 [00:07<00:53,  1.97s/cell]Executing:  17%|â–ˆâ–‹        | 5/30 [02:17<14:19, 34.39s/cell]Executing:  20%|â–ˆâ–ˆ        | 6/30 [02:17<10:04, 25.19s/cell]Executing:  27%|â–ˆâ–ˆâ–‹       | 8/30 [02:17<05:14, 14.29s/cell]Executing:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 10/30 [02:19<03:00,  9.04s/cell]Executing:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 12/30 [02:19<01:45,  5.88s/cell]Executing:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 14/30 [02:19<01:02,  3.94s/cell]Executing:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 16/30 [02:19<00:37,  2.69s/cell]Executing:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 17/30 [02:21<00:32,  2.48s/cell]Executing:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 19/30 [02:21<00:18,  1.64s/cell]Executing:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 21/30 [02:21<00:10,  1.13s/cell]Executing:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 23/30 [02:21<00:05,  1.26cell/s]Executing:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 24/30 [42:23<45:00, 450.05s/cell]Executing:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 24/30 [42:26<10:36, 106.10s/cell]
Traceback (most recent call last):
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/Kaggle_2/venv/bin/papermill", line 7, in <module>
    sys.exit(papermill())
             ^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/Kaggle_2/venv/lib/python3.11/site-packages/click/core.py", line 1485, in __call__
    return self.main(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/Kaggle_2/venv/lib/python3.11/site-packages/click/core.py", line 1406, in main
    rv = self.invoke(ctx)
         ^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/Kaggle_2/venv/lib/python3.11/site-packages/click/core.py", line 1269, in invoke
    return ctx.invoke(self.callback, **ctx.params)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/Kaggle_2/venv/lib/python3.11/site-packages/click/core.py", line 824, in invoke
    return callback(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/Kaggle_2/venv/lib/python3.11/site-packages/click/decorators.py", line 34, in new_func
    return f(get_current_context(), *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/Kaggle_2/venv/lib/python3.11/site-packages/papermill/cli.py", line 235, in papermill
    execute_notebook(
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/Kaggle_2/venv/lib/python3.11/site-packages/papermill/execute.py", line 131, in execute_notebook
    raise_for_execution_errors(nb, output_path)
  File "/gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/Kaggle_2/venv/lib/python3.11/site-packages/papermill/execute.py", line 251, in raise_for_execution_errors
    raise error
papermill.exceptions.PapermillExecutionError: 
---------------------------------------------------------------------------
Exception encountered at "In [15]":
---------------------------------------------------------------------------
SchemaError                               Traceback (most recent call last)
Cell In[15], line 8
      5 print("="*80)
      7 # Process each dataset
----> 8 process_features_chunked(data_files['train'], 'train', has_label=True)
      9 process_features_chunked(data_files['val'], 'val', has_label=True)
     10 process_features_chunked(data_files['test'], 'test', has_label=False)

Cell In[11], line 112, in process_features_chunked(file_path, dataset_name, has_label)
    110 print(f"\nðŸ“‚ Merging chunks...")
    111 output_file = RESULTS_DIR / f'X_{dataset_name}.parquet'
--> 112 merge_chunk_files(f'features_{dataset_name}_chunk_*.parquet', output_file)
    114 # Final save of labels (ensure it's saved even if merge fails)
    115 if has_label and labels:

Cell In[6], line 108, in merge_chunk_files(chunk_pattern, output_file, cleanup)
    105     aligned_dfs.append(df)
    107 # Now concatenate with aligned schemas
--> 108 merged_df = pl.concat(aligned_dfs)
    110 # Save merged file
    111 merged_df.write_parquet(output_file)

File /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/Kaggle_2/venv/lib/python3.11/site-packages/polars/functions/eager.py:231, in concat(items, how, rechunk, parallel)
    229 if isinstance(first, pl.DataFrame):
    230     if how == "vertical":
--> 231         out = wrap_df(plr.concat_df(elems))
    232     elif how == "vertical_relaxed":
    233         out = wrap_ldf(
    234             plr.concat_lf(
    235                 [df.lazy() for df in elems],
   (...)    240             )
    241         ).collect(optimizations=QueryOptFlags._eager())

SchemaError: type UInt8 is incompatible with expected type Int64

âœ— ERROR: Papermill failed after 2558s!
Check notebook for errors in logs/data-explore-*.err
Check execution logs: /gpfs/accounts/si670f25_class_root/si670f25_class/santoshd/Kaggle_2/logs/notebook_execution.log
